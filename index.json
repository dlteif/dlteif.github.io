[{"authors":["admin"],"categories":null,"content":"I am a fifth year Computer Science PhD candidate at Boston University in the Image and Video Computing Group and a member of the Kolachalama Laboratory at the BU School of Medicine. I am advised by Professors Sarah Adel Bargal, Bryan A. Plummer, and Vijaya B. Kolachalama. Before joining BU, I received a Bachelor's degree in Computer Science at the American University of Beirut, Lebanon. My research interests fall under the umbrella of explainable AI, efficient machine learning and computer vision. I am interested in improving applications at the intersection of AI and health care through interpretable, efficient and trustworthy machine learning models. My thesis revolves around learning robust and generalizable representations of neuro-imaging data for the assessment of Alzheimer's disease and related neurodegnerative disorders. Graduate Coursework CS542 Machine Learning CS640 Artificial Intelligence CS585 Image and Video Computing CS535 Complexity Theory CS530 Advanced Algorithms CS552 Introduction to Operating Systems CS511 Formal Methods I ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dlteif.github.io/author/diala-lteif/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/diala-lteif/","section":"authors","summary":"I am a fifth year Computer Science PhD candidate at Boston University in the Image and Video Computing Group and a member of the Kolachalama Laboratory at the BU School of Medicine.","tags":null,"title":"Diala Lteif","type":"authors"},{"authors":["Chonghua Xue*","Sahana S. Kowshik*","Diala Lteif","Shreyas Puducheri","Varuna H. Jasodanand","Olivia T. Zhou","Anika S. Walia","Osman B. Guney","J. Diana Zhang","Serena T. Pham","Artem Kaliaev","V. Carlota Andreu-Arasa","Brigid C. Dwyer","Chad W. Farris","Honglin Hao","Sachin Kedar","Asim Z. Mian","Daniel L. Murman","Sarah A. O’Shea","Aaron B. Paul","Saurabh Rohatgi","Marie-Helene Saint-Hilaire","Emmett A. Sartor","Bindu N. Setty","Juan E. Small","Arun Swaminathan","Olga Taraschenko","Jing Yuan","Yan Zhou","Shuhan Zhu","Cody Karjadi","Ting Fang Alvin Ang","Sarah A. Bargal","Bryan A. Plummer","Kathleen L. Poston","Meysam Ahangaran","Rhoda Au","Vijaya B. Kolachalama"],"categories":[],"content":"","date":1711411200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711411200,"objectID":"cb309ce381d3665d5da8a0f47d0ba84f","permalink":"https://dlteif.github.io/publication/adrd/","publishdate":"2024-03-26T00:00:00Z","relpermalink":"/publication/adrd/","section":"publication","summary":"Differential diagnosis of dementia remains a challenge in neurology due to symptom overlap across etiologies, yet it is crucial for formulating early, personalized management strategies. Here, we present an AI model that harnesses a broad array of data, including demographics, individual and family medical history, medication use, neuropsychological assessments, functional evaluations, and multimodal neuroimaging, to identify the etiologies contributing to dementia in individuals. The study, drawing on 51,269 participants across 9 independent, geographically diverse datasets, facilitated the identification of 10 distinct dementia etiologies. It aligns diagnoses with similar management strategies, ensuring robust predictions even with incomplete data. Our model achieved a micro-averaged area under the receiver operating characteristic curve (AUROC) of 0.94 in classifying individuals with normal cognition, mild cognitive impairment and dementia. Also, the micro-averaged AUROC was 0.96 in differentiating the dementia etiologies. Our model demonstrated proficiency in addressing mixed dementia cases, with a mean AUROC of 0.78 for two co-occurring pathologies. In a randomly selected subset of 100 cases, the AUROC of neurologist assessments augmented by our AI model exceeded neurologist-only evaluations by 26.25%. Furthermore, our model predictions aligned with biomarker evidence and its associations with different proteinopathies were substantiated through postmortem findings. Our framework has the potential to be integrated as a screening tool for dementia in various clinical settings and drug trials, with promising implications for person-level management.","tags":[],"title":"AI-based differential diagnosis of dementia etiologies on multimodal data.","type":"publication"},{"authors":["Diala Lteif","Sandeep Sreerama","Sarah Adel Bargal","Bryan A. Plummer","Rhoda Au","Vijaya B. Kolachalama"],"categories":[],"content":"","date":1695340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695340800,"objectID":"fd443763c0e708e469a6d13f3225b1a2","permalink":"https://dlteif.github.io/publication/d3g/","publishdate":"2023-09-22T00:00:00Z","relpermalink":"/publication/d3g/","section":"publication","summary":"Development of deep learning models to assess the degree of cognitive impairment on magnetic resonance imaging (MRI) scans has high translational significance. Performance of such models is often affected by potential variabilities stemming from independent protocols for data generation, imaging equipment, radiology artifacts, and demographic distributional shifts. Domain generalization (DG) frameworks have the potential to overcome these issues by learning signal from one or more source domains that can be transferable to unseen target domains. We developed an approach that leverages model interpretability as a means to improve generalizability of classification models across multiple cohorts. Using MRI scans and clinical diagnosis obtained from four independent cohorts (Alzheimer’s Disease Neuroimaging Initiative (ADNI, n = 1, 821), the Framingham Heart Study (FHS, n = 304), the Australian Imaging Biomarkers and Lifestyle Study of Ageing (AIBL, n = 661), and the National Alzheimer’s Coordinating Center (NACC, n = 4, 647)), we trained a deep neural network that used model-identified regions of disease relevance to inform model training. We trained a classifier to distinguish persons with normal cognition (NC) from those with mild cognitive impairment (MCI) and Alzheimer’s disease (AD) by aligning class-wise attention with a unified visual saliency prior computed offline per class over all training data. Our proposed method competes with state-of-the-art methods with improved correlation with postmortem histology, thus grounding our findings with gold standard evidence and paving a way towards validating DG frameworks.","tags":[],"title":"Disease-driven domain generalization for neuroimaging-based assessment of Alzheimer’s disease.","type":"publication"},{"authors":["Shoumik Sovan Majumdar*","Shubhangi Jain*","Isidora Chara Tourni*","Arsenii Mustafin","Diala Lteif","Stan Sclaroff","Kate Saenko","Sarah Adel Bargal"],"categories":[],"content":"","date":1664172706,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669788706,"objectID":"0f2d06f0be321945b969059b7c666f9e","permalink":"https://dlteif.github.io/publication/anigifs/","publishdate":"2022-09-26T00:11:46-06:00","relpermalink":"/publication/anigifs/","section":"publication","summary":"Deep learning models perform remarkably well for the same task under the assumption that data is always coming from the same distribution. However, this is generally violated in practice, mainly due to the differences in data acquisition techniques and the lack of information about the underlying source of new data. Domain generalization targets the ability to generalize to test data of an unseen domain; while this problem is well-studied for images, such studies are significantly lacking in spatiotemporal visual content—videos and GIFs. This is due to (1) the challenging nature of misalignment of temporal features and the varying appearance/motion of actors and actions in different domains, and (2) spatiotemporal datasets being laborious to collect and annotate for multiple domains. We collect and present the first synthetic video dataset of Animated GIFs for domain generalization, Ani-GIFs, that is used to study the domain gap of videos vs. GIFs, and animated vs. real GIFs, for the task of action recognition. We provide a training and testing setting for Ani-GIFs, and extend two domain generalization baseline approaches, based on data augmentation and explainability, to the spatiotemporal domain to catalyze research in this direction.","tags":[],"title":"Ani-GIFs: A benchmark dataset for domain generalization of action recognition from GIFs.","type":"publication"}]